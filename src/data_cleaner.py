import numpy as np
import pandas as pd
from scipy import stats

def remove_outliers_iqr(data, column, factor=1.5):
    """
    Remove outliers using IQR method.
    """
    q1 = data[column].quantile(0.25)
    q3 = data[column].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - factor * iqr
    upper_bound = q3 + factor * iqr
    filtered_data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
    return filtered_data

def normalize_minmax(data, column):
    """
    Normalize data using min-max scaling.
    """
    min_val = data[column].min()
    max_val = data[column].max()
    data[column + '_normalized'] = (data[column] - min_val) / (max_val - min_val)
    return data

def z_score_normalize(data, column):
    """
    Normalize data using z-score method.
    """
    mean_val = data[column].mean()
    std_val = data[column].std()
    data[column + '_zscore'] = (data[column] - mean_val) / std_val
    return data

def clean_dataset(df, numeric_columns, outlier_factor=1.5):
    """
    Clean dataset by removing outliers and normalizing numeric columns.
    """
    cleaned_df = df.copy()
    
    for col in numeric_columns:
        if col in cleaned_df.columns:
            cleaned_df = remove_outliers_iqr(cleaned_df, col, outlier_factor)
            cleaned_df = normalize_minmax(cleaned_df, col)
            cleaned_df = z_score_normalize(cleaned_df, col)
    
    return cleaned_df

def validate_data(df, required_columns):
    """
    Validate that required columns exist and have no null values.
    """
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"Missing required columns: {missing_columns}")
    
    null_counts = df[required_columns].isnull().sum()
    if null_counts.any():
        raise ValueError(f"Null values found in columns: {null_counts[null_counts > 0].to_dict()}")
    
    return True

def sample_data_cleaning():
    """
    Example usage of data cleaning functions.
    """
    np.random.seed(42)
    sample_data = pd.DataFrame({
        'id': range(100),
        'value': np.random.normal(100, 15, 100),
        'measurement': np.random.exponential(50, 100)
    })
    
    print("Original data shape:", sample_data.shape)
    print("Original data summary:")
    print(sample_data.describe())
    
    cleaned_data = clean_dataset(sample_data, ['value', 'measurement'])
    
    print("\nCleaned data shape:", cleaned_data.shape)
    print("Cleaned data summary:")
    print(cleaned_data[['value_normalized', 'value_zscore', 
                       'measurement_normalized', 'measurement_zscore']].describe())
    
    return cleaned_data

if __name__ == "__main__":
    cleaned = sample_data_cleaning()
    print(f"\nData cleaning completed. Final dataset has {len(cleaned)} rows.")